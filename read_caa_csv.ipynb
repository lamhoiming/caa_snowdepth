{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Translating read_caa_csv.R into Python\n",
    "Lam Hoi Ming\n",
    "02-07-2019\n",
    "\n",
    "Data processing is done on the original csv file. Separated into files by station\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ data input #################\n",
    "#### set data input working directory: Where are your data?\n",
    "Mdir = \"d:/phd/caa/eccc/snowdepth/\"   # Master/root dir\n",
    "wdir = Mdir + \"data/station/csv/\" # specific working dir\n",
    "os.chdir(wdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting station ID\n",
    "# Lat lon info are stored in idname\n",
    "idname = pd.read_csv('ID_NAME.csv', encoding = \"utf-8\", sep = ',', index_col = 'StationID') # ISO-8859-1 for ASCII\n",
    "idname.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stations\n",
    "list_stn = [\n",
    "  # West of 100W, no 2016\n",
    "  \"CAPE PARRY ZUE\", \n",
    "  \"COPPERMINE YCO\",\n",
    "  \"HOLMAN ISLAND YHI\",\n",
    "  \"ISACHSEN (OLD ICE) IC1\",   #no trend by month\n",
    "  \"ISACHSEN YIC\",\n",
    "  \"LADY FRANKLIN POINT YUJ\",\n",
    "  \"MOULD BAY YMD\",\n",
    "  \"SACHS HARBOUR YSY\", \n",
    "  # current stations up to 2016\n",
    "  \"ALERT LT1\", \n",
    "    \"ALERT YLT\", \n",
    "    \"CAMBRIDGE BAY YCB\", \n",
    "    \"CORAL HARBOUR YZS\", \n",
    "    \"EUREKA WEU\", \n",
    "    \"HALL BEACH YUX\", \n",
    "    \"IQALUIT YFB\", \n",
    "    \"RESOLUTE YRB\", # with 2016 data\n",
    "  # East of 100W, in hudson bay, no 2016\n",
    "  \"ARCTIC BAY YAB\",\n",
    "  \"CAPE DORSET YTE\",\n",
    "  \"CHESTERFIELD INLET YCS\",\n",
    "  \"CHURCHILL YYQ\",\n",
    "  \"CLYDE YCY\",\n",
    "  \"GLADMAN POINT YUR\",\n",
    "  \"INUKJUAK PH1\",\n",
    "  \"INUKJUAK WPH\",                 #no trend by month\n",
    "  \"IQALUIT YFB\",              \n",
    "  \"KUUJJUAQ YVP\",\n",
    "  \"KUUJJUARAPIK YGW\",\n",
    "  \"MOOSONEE WZC\",\n",
    "  \"POND INLET YIO\",\n",
    "  \"QUAQTAQ HA1\",\n",
    "  \"QUAQTAQ YHA\",\n",
    "  \"SHEPHERD BAY YUS\",              #no trend by month\n",
    "  \"SPENCE BAY YNC\",              \n",
    "  #inland stations for comparison\n",
    "  \"BAKER LAKE YBK\",\n",
    "  \"INUVIK YEV\"\n",
    "  # Further southeast around Labrador sea/PEI?\n",
    "]\n",
    "print(list_stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_station():\n",
    "    for i, station in enumerate(list_stn):\n",
    "#         if idname.StationName.str.match(station).bool:\n",
    "        ID = idname.index[idname.StationName == station].format()\n",
    "        print(station)\n",
    "        fdata[station] = pd.read_csv(ID[0] + '.csv', parse_dates = [0], infer_datetime_format=True, index_col = 'Date')\n",
    "#         else:\n",
    "#             print('nothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = {}\n",
    "read_station()\n",
    "# fdata['ALERT YLT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month list from August\n",
    "#sep_jul <- c(\"S\", \"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\")\n",
    "aug_jul = [\"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\"]\n",
    "A_J = [\"A\",\"S\", \"O\", \"N\", \"D\", \"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING SNOW DEPTH FROM EACH STATION\n",
    "def read_snowdepth(data):\n",
    "    for i, station in enumerate(list_stn):\n",
    "        stn_title = station.replace(' ', '_')\n",
    "        print(stn_title)\n",
    "        stn_snow[station] = pd.DataFrame({'snow_depth':data[station]['Snowdepth']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_snow = {}\n",
    "read_snowdepth(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After reading the snow depth vs date, now manipulate in different ways\n",
    "#Function to plot time series for all stations\n",
    "def full_time_series(stn_data,save_directory):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
